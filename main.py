import io
import os
import re
import pdfplumber
import pandas as pd
import streamlit as st
import numpy as np

import plotly.express as px
import plotly.graph_objects as go

st.set_page_config(page_title="ì„œìš¸ì‹œë¯¼ ê²°í˜¼Â·ê°€ì¡± ë³€í™” ë¶„ì„ (Plotly ë²„ì „)", layout="wide")

# ---------------------------
# ê³ ì • íŒŒì¼ ê²½ë¡œ (main.pyì™€ ë™ì¼ í´ë”)
# ---------------------------
PDF_FILENAME = "ì„œìš¸ì‹œë¯¼ì˜+ê²°í˜¼ê³¼+ê°€ì¡±+í˜•íƒœì˜+ë³€í™”+ë¶„ì„.pdf"
PDF_PATH = os.path.join(os.path.dirname(__file__), PDF_FILENAME)

METRICS_CSV_NAME = "seoul_family_metrics.csv"
METRICS_CSV_PATH = os.path.join(os.path.dirname(__file__), METRICS_CSV_NAME)

# ---------------------------
# ìºì‹œ ìœ í‹¸
# ---------------------------
@st.cache_data(show_spinner=False)
def read_pdf_bytes(path: str) -> bytes:
    with open(path, "rb") as f:
        return f.read()

@st.cache_data(show_spinner=False)
def extract_text_from_pdf(file_bytes: bytes) -> str:
    text_chunks = []
    with pdfplumber.open(io.BytesIO(file_bytes)) as pdf:
        for page in pdf.pages:
            t = page.extract_text(x_tolerance=1.5, y_tolerance=1.5) or ""
            t = re.sub(r"[ \t]+", " ", t)
            text_chunks.append(t.strip())
    return "\n\n".join(text_chunks)

def split_sentences_rough_korean(text: str):
    # ë§ˆì¹¨í‘œ/ë¬¼ìŒí‘œ/ëŠë‚Œí‘œ/ê°œí–‰ ê¸°ì¤€ ê°„ë‹¨ ë¶„ë¦¬
    sents = re.split(r'(?<=[.!?])\s+|\n+', text)
    return [s.strip() for s in sents if len(s.strip()) > 1]

def keyword_hits(sentences, kw):
    kw_norm = kw.lower()
    rows = []
    for i, s in enumerate(sentences):
        if kw_norm in s.lower():
            rows.append({"keyword": kw, "sentence_idx": i, "sentence": s})
    return rows

def make_snippet(hit, window=160):
    s = hit["sentence"]
    if len(s) <= window:
        return s
    return s[: window//2] + " â€¦ " + s[-window//2 :]

@st.cache_data(show_spinner=False)
def load_metrics_csv(path: str):
    if not os.path.exists(path):
        return None
    df = pd.read_csv(path)
    if "year" in df.columns:
        df["year"] = pd.to_numeric(df["year"], errors="coerce").astype("Int64")
        df = df.sort_values("year")
    return df

def make_metrics_template_df():
    cols = [
        "year",
        "marriage_rate",            # í˜¼ì¸ìœ¨
        "first_marriage_age_m",     # ë‚¨ì í‰ê·  ì´ˆí˜¼ì—°ë ¹
        "first_marriage_age_f",     # ì—¬ì í‰ê·  ì´ˆí˜¼ì—°ë ¹
        "divorce_rate",             # ì´í˜¼ìœ¨
        "tfr",                      # í•©ê³„ì¶œì‚°ìœ¨
        "one_person_share"          # 1ì¸ ê°€êµ¬ ë¹„ì¤‘(%)
    ]
    years = [2015, 2018, 2020, 2022, 2024]
    df = pd.DataFrame({c: [None]*len(years) for c in cols})
    df["year"] = years
    return df[cols]

def melt_for_line(df, year_col, metric_cols):
    d = df[[year_col] + metric_cols].copy()
    # ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜
    for c in metric_cols:
        d[c] = pd.to_numeric(d[c], errors="coerce")
    long = d.melt(id_vars=year_col, value_vars=metric_cols,
                  var_name="metric", value_name="value")
    return long

def corr_dataframe(df, cols):
    d = df[cols].apply(pd.to_numeric, errors="coerce")
    return d.corr()

# ---------------------------
# ì‚¬ì´ë“œë°” - ê³µí†µ ë¶„ì„ ì„¤ì •
# ---------------------------
st.sidebar.header("ğŸ” í…ìŠ¤íŠ¸ ë¶„ì„ ì„¤ì •")
default_keywords = [
    "í˜¼ì¸ìœ¨", "ì´ˆí˜¼", "ì¬í˜¼", "ì´í˜¼", "ì¶œì‚°", "í•©ê³„ì¶œì‚°ìœ¨",
    "1ì¸ ê°€êµ¬", "ë¹„í˜¼", "ë§Œí˜¼", "ë™ê±°", "ê°€ì¡±í˜•íƒœ", "ì¶œìƒ", "ê³ ë ¹í™”"
]
keywords = st.sidebar.text_area(
    "ê´€ì‹¬ í‚¤ì›Œë“œ(ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)",
    value="\n".join(default_keywords),
    height=180
).splitlines()
keywords = [k.strip() for k in keywords if k.strip()]
context_window = st.sidebar.slider("ë¬¸ë§¥ ìŠ¤ë‹ˆí« ê¸¸ì´(ë¬¸ììˆ˜)", 60, 400, 160, 20)

st.sidebar.header("ğŸ“ˆ ì§€í‘œ ëŒ€ì‹œë³´ë“œ ì„¤ì •")
metric_defaults = ["marriage_rate", "tfr", "one_person_share"]
selected_metrics = st.sidebar.text_input(
    "í‘œì‹œí•  ì§€í‘œ(ì‰¼í‘œë¡œ êµ¬ë¶„)",
    value=", ".join(metric_defaults)
)
selected_metrics = [m.strip() for m in selected_metrics.split(",") if m.strip()]

# ---------------------------
# ìƒë‹¨ ì •ë³´
# ---------------------------
st.title("ğŸ“Š ì„œìš¸ì‹œë¯¼ì˜ ê²°í˜¼Â·ê°€ì¡± í˜•íƒœ ë³€í™” â€” Plotly ëŒ€ì‹œë³´ë“œ")
st.caption("ê°™ì€ í´ë”ì˜ PDFì™€ CSVë¥¼ ì§ì ‘ ì½ì–´ ë¶„ì„í•©ë‹ˆë‹¤.")
st.write(f"PDF íŒŒì¼: **{PDF_FILENAME}**")
st.caption(f"ê²½ë¡œ: `{PDF_PATH}`")

# ---------------------------
# íƒ­ êµ¬ì„±
# ---------------------------
tab1, tab2 = st.tabs(["ğŸ“° í…ìŠ¤íŠ¸ ë¶„ì„ (PDF)", "ğŸ“Š ì§€í‘œ ëŒ€ì‹œë³´ë“œ (CSV)"])

# ===========================
# íƒ­ 1: í…ìŠ¤íŠ¸ ë¶„ì„
# ===========================
with tab1:
    if not os.path.exists(PDF_PATH):
        st.error("ì§€ì •ëœ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. `main.py`ì™€ ê°™ì€ í´ë”ì— "
                 f"`{PDF_FILENAME}` íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

    with st.spinner("PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘â€¦"):
        raw_bytes = read_pdf_bytes(PDF_PATH)
        raw_text = extract_text_from_pdf(raw_bytes)

    sentences = split_sentences_rough_korean(raw_text)
    st.success(f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ: ì•½ {len(sentences)}ê°œ ë¬¸ì¥")

    # í‚¤ì›Œë“œ ê²€ìƒ‰/ì‹œê°í™”
    hits_all = []
    for kw in keywords:
        hits_all.extend(keyword_hits(sentences, kw))

    if hits_all:
        df_hits = pd.DataFrame(hits_all)
        counts = (
            df_hits["keyword"]
            .value_counts()
            .rename_axis("keyword")
            .reset_index(name="count")
            .sort_values("count", ascending=False)
        )

        st.subheader("ğŸ“ˆ í‚¤ì›Œë“œ ì¶œí˜„ ë¹ˆë„ (Plotly)")
        fig_bar = px.bar(
            counts,
            x="keyword",
            y="count",
            text="count",
            title="Keyword Frequency",
        )
        fig_bar.update_traces(textposition="outside")
        fig_bar.update_layout(xaxis_title="í‚¤ì›Œë“œ", yaxis_title="ë¹ˆë„", margin=dict(t=60))
        st.plotly_chart(fig_bar, use_container_width=True)

        st.subheader("ğŸ§© ë¬¸ë§¥ ìŠ¤ë‹ˆí«")
        df_hits["snippet"] = df_hits.apply(lambda r: make_snippet(r, context_window), axis=1)
        show_cols = ["keyword", "sentence_idx", "snippet"]
        st.dataframe(df_hits[show_cols], use_container_width=True, height=360)

        csv = df_hits[show_cols + ["sentence"]].to_csv(index=False).encode("utf-8-sig")
        st.download_button("CSVë¡œ ë‚´ë³´ë‚´ê¸°", data=csv, file_name="keyword_snippets.csv", mime="text/csv")
    else:
        st.info("ì„¤ì •í•œ í‚¤ì›Œë“œê°€ ë³¸ë¬¸ì—ì„œ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¡°ì •í•´ ë³´ì„¸ìš”.")

    # ê°„ë‹¨ ìš”ì•½
    st.subheader("ğŸ“ ê°„ë‹¨ ìš”ì•½(ë£° ê¸°ë°˜)")
    years = sorted(set(re.findall(r"\b(19\d{2}|20\d{2})\b", raw_text)))
    bullets = []
    if years:
        bullets.append(f"- ë³´ê³ ì„œì— ë“±ì¥í•˜ëŠ” ì—°ë„ ë²”ìœ„: **{years[0]}â€“{years[-1]}**")
    for term in ["í˜¼ì¸ìœ¨", "ì´ˆí˜¼", "ì´í˜¼", "ì¶œì‚°", "í•©ê³„ì¶œì‚°ìœ¨", "1ì¸ ê°€êµ¬", "ë¹„í˜¼", "ë™ê±°", "ë§Œí˜¼"]:
        if re.search(term, raw_text):
            bullets.append(f"- **{term}** ê´€ë ¨ ì„œìˆ ì´ í¬í•¨ë˜ì–´ ìˆìŒ")
    if not bullets:
        bullets.append("- ì£¼ìš” ìš©ì–´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í‚¤ì›Œë“œ/ìŠ¤ë‹ˆí« ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.")
    for b in bullets:
        st.markdown(b)

    with st.expander("ğŸ“„ ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°"):
        st.text_area("í…ìŠ¤íŠ¸(ì¼ë¶€)", value=raw_text[:8000], height=260)

# ===========================
# íƒ­ 2: ì§€í‘œ ëŒ€ì‹œë³´ë“œ
# ===========================
with tab2:
    st.write(f"CSV íŒŒì¼(ì„ íƒ): **{METRICS_CSV_NAME}**")
    st.caption(f"ê²½ë¡œ: `{METRICS_CSV_PATH}`")

    dfm = load_metrics_csv(METRICS_CSV_PATH)

    if dfm is None:
        st.warning("ì§€í‘œ CSVê°€ ì—†ìŠµë‹ˆë‹¤. ì•„ë˜ í…œí”Œë¦¿ì„ ë‚´ë ¤ë°›ì•„ ìˆ˜ì¹˜ë¥¼ ì±„ìš´ ë’¤ "
                   f"`{METRICS_CSV_NAME}` ì´ë¦„ìœ¼ë¡œ ê°™ì€ í´ë”ì— ì €ì¥í•˜ì„¸ìš”.")
        template_df = make_metrics_template_df()
        st.dataframe(template_df, use_container_width=True, height=240)

        csv_bytes = template_df.to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            "ì§€í‘œ í…œí”Œë¦¿ CSV ë‹¤ìš´ë¡œë“œ",
            data=csv_bytes,
            file_name=METRICS_CSV_NAME,
            mime="text/csv"
        )
    else:
        st.success("ì§€í‘œ CSV ë¡œë“œ ì™„ë£Œ")
        st.dataframe(dfm, use_container_width=True, height=300)

        # ì„ íƒ ì§€í‘œ ìœ íš¨ì„± í•„í„°
        numeric_cols = [c for c in dfm.columns if c != "year"]
        active_cols = [c for c in selected_metrics if c in dfm.columns and c != "year"]
        if not active_cols:
            active_cols = [c for c in metric_defaults if c in dfm.columns]

        # ----- ì‹œê³„ì—´ ë¼ì¸ì°¨íŠ¸ (Plotly) -----
        st.subheader("ğŸ“ˆ ì‹œê³„ì—´ ë¼ì¸ì°¨íŠ¸ (Plotly)")
        try:
            long = melt_for_line(dfm, "year", active_cols)
            fig_line = px.line(
                long,
                x="year",
                y="value",
                color="metric",
                markers=True,
                title="Selected Metrics Over Time"
            )
            fig_line.update_layout(
                xaxis_title="year",
                yaxis_title="value",
                hovermode="x unified",
                margin=dict(t=60)
            )
            st.plotly_chart(fig_line, use_container_width=True)
        except Exception as e:
            st.error(f"ë¼ì¸ì°¨íŠ¸ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

        # ----- ì „ë…„ ëŒ€ë¹„ ì¦ê°ë¥  -----
        st.subheader("â†•ï¸ ì „ë…„ ëŒ€ë¹„ ì¦ê°ë¥ (%)")
        pct_df = dfm[["year"] + active_cols].copy()
        for col in active_cols:
            pct_df[col] = pd.to_numeric(pct_df[col], errors="coerce")
            pct_df[col] = pct_df[col].pct_change() * 100.0
        st.dataframe(pct_df, use_container_width=True, height=220)

        # ì¦ê°ë¥  ë¼ì¸(ì˜µì…˜)
        try:
            long_pct = melt_for_line(pct_df, "year", active_cols)
            fig_pct = px.line(
                long_pct,
                x="year",
                y="value",
                color="metric",
                markers=True,
                title="YoY Change (%)"
            )
            fig_pct.update_layout(xaxis_title="year", yaxis_title="pct_change(%)", hovermode="x unified")
            st.plotly_chart(fig_pct, use_container_width=True)
        except Exception:
            pass

        # ----- ìƒê´€í–‰ë ¬ (Plotly Heatmap) -----
        st.subheader("ğŸ”— ì§€í‘œ ìƒê´€í–‰ë ¬")
        try:
            corr_cols = [c for c in active_cols if c in dfm.columns]
            if len(corr_cols) >= 2:
                corr = corr_dataframe(dfm, corr_cols)
                # íˆíŠ¸ë§µ + ê°’ í‘œì‹œ
                heat = go.Heatmap(
                    z=corr.values,
                    x=corr_cols,
                    y=corr_cols,
                    zmin=-1, zmax=1,
                    colorbar=dict(title="corr")
                )
                fig_corr = go.Figure(data=[heat])
                # ê°’ annotation
                annotations = []
                for i, row in enumerate(corr.values):
                    for j, val in enumerate(row):
                        annotations.append(
                            dict(
                                x=corr_cols[j],
                                y=corr_cols[i],
                                text=f"{val:.2f}",
                                xref="x1", yref="y1",
                                showarrow=False
                            )
                        )
                fig_corr.update_layout(
                    title="Correlation Matrix",
                    annotations=annotations,
                    margin=dict(t=60)
                )
                st.plotly_chart(fig_corr, use_container_width=True)
            else:
                st.info("ìƒê´€í–‰ë ¬ì„ ë³´ë ¤ë©´ 2ê°œ ì´ìƒì˜ ì§€í‘œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ìƒê´€í–‰ë ¬ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
